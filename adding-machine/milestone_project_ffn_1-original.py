# -*- coding: utf-8 -*-
"""Milestone Project FFN 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rK9Hw_AUz8CLht9NAqteqKfSNkedzZEr

**Importar pacotes**
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
import matplotlib_inline.backend_inline
matplotlib_inline.backend_inline.set_matplotlib_formats('svg')

"""**Criação dos dados**"""

N = 380

entrada = torch.randint(-10,11,(N,2)).float()
print(entrada)
saida = torch.sum(entrada, axis=1,keepdim=True)
print(saida)

# print the data
for i in range(N):
  print(entrada[i],saida[i])

"""**Conjunto de treinamento e teste usando DataLoader**

"""

# Converter para tensor
# dataT  = torch.tensor(entrada).float()
# saidaT = torch.tensor(saida).long()

# Dividir o conjunto de dados
train_data,test_data,train_saida,test_saida = train_test_split(entrada, saida, test_size=.2)

# Converter os dados para PyTorch
train_data = torch.utils.data.TensorDataset(train_data,train_saida)
test_data  = torch.utils.data.TensorDataset(test_data,test_saida)

# Traduzir para objetos em dataloader
batchsize    = 16
train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)
test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])

"""**Create the DL model**"""

def createSumModel(nUnits,nLayers):

  class sumModel(nn.Module):
    def __init__(self,nUnits,nLayers):
      super().__init__()

      # create dictionary to store the layers
      self.layers = nn.ModuleDict()
      self.nLayers = nLayers

      ### input layer
      self.layers['input'] = nn.Linear(2,nUnits)

      ### hidden layers
      for i in range(nLayers):
        self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)

      ### output layer
      self.layers['output'] = nn.Linear(nUnits,1)

    # forward pass
    def forward(self,x):
      # input layer (note: the code in the video omits the relu after this layer)
      x = F.relu( self.layers['input'](x) )

      # hidden layers
      for i in range(self.nLayers):
        x = F.relu( self.layers[f'hidden{i}'](x) )

      # return output layer
      x = self.layers['output'](x)
      return x

  # create the model instance
  net = sumModel(nUnits,nLayers)

  # loss function
  #lossfun = nn.CrossEntropyLoss()
  lossfun = nn.MSELoss()

  # optimizer
  optimizer = torch.optim.SGD(net.parameters(),lr=.01)

  return net,lossfun,optimizer

"""**Dimensões da rede neural**"""

# Generate an instance of the model and confirm that it returns the expected network.
nUnitsPerLayer = 15
nLayers = 2
net = createSumModel(nUnitsPerLayer,nLayers)
net

"""**Treinamento da rede**"""

def function2trainTheModel(nUnits,nLayers):

  # number of epochs
  numepochs = 60

  # create a new model
  net,lossfun,optimizer = createSumModel(nUnits,nLayers)

  # initialize losses
  losses    = torch.zeros(numepochs)
  trainAcc  = []
  testAcc   = []


  # loop over epochs
  for epochi in range(numepochs):

    # loop over training data batches
    batchAcc  = []
    batchLoss = []
    for X,y in train_loader:

      # forward pass and loss
      yHat = net(X)
      print(yHat)
      print(y)
      loss = lossfun(yHat,y)

      # backprop
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      # loss from this batch
      batchLoss.append(loss.item())

      # compute accuracy
      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)
      matchesNumeric = matches.float()             # convert to numbers (0/1)
      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100
      batchAcc.append( accuracyPct )               # add to list of accuracies
    # end of batch loop...

    # now that we've trained through the batches, get their average training accuracy
    trainAcc.append( np.mean(batchAcc) )

    # and get average losses across the batches
    losses[epochi] = np.mean(batchLoss)

    # test accuracy
    X,y = next(iter(test_loader))     # extract X,y from test dataloader
    with torch.no_grad():             # deactivates autograd
      yHat = net(X)

    # compare the following really long line of code to the training accuracy lines
    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )
    print(trainAcc)
  # end epochs

  # function output
  return trainAcc,testAcc,losses,net

"""**Run the model and show the results**"""

# run the model 10 times to check reproducibility
train_accuracies = []
test_accuracies = []
# train_losses = []
# test_losses = []

for i in range(10):
  # create a new machine and train it
  # sumModel,lossfun,optimizer = createSumModel(15,2)
  accTrain, accTest,losses, predictions = function2trainTheModel(25,2)
  print("Train=")
  print(accTrain)
  accTrainMean = (sum(accTrain)/len(accTrain))/100
  accTestMean = (sum(accTest)/len(accTest))/100
  train_accuracies.append(accTrainMean)
  test_accuracies.append(accTestMean)

train_accuracies = np.array(train_accuracies)
test_accuracies = np.array(test_accuracies)

print(train_accuracies)
print(test_accuracies)

fig, ax = plt.subplots(1, 2, figsize=(14, 5))
x = np.arange(1, 11)

# Gráfico de acurácia
ax[0].plot(x, train_accuracies, label='Train Accuracy', marker='o')
ax[0].plot(x, test_accuracies, label='Test Accuracy', marker='s')

ax[0].set_title('Accuracy per Run')
ax[0].set_xlabel('Run')
ax[0].set_ylabel('Accuracy')
#ax[0].set_ylim(0, 1)
ax[0].legend()

plt.suptitle('Results of 10 Model Runs (15 units, 2 layers)', fontsize=14)
plt.tight_layout()
plt.show()